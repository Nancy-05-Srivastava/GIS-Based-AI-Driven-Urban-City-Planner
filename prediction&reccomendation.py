# -*- coding: utf-8 -*-
"""Prediction&Reccomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kXGo8UL6SZOKJrAJnFgq_QI4bMxVLrWy
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data_path = "training_dataset_20000.csv"
df = pd.read_csv(data_path)

# Explore the data
print(df.info())
print(df.describe())

# Check for outliers in the target variable
sns.boxplot(y=df["Biodiversity_Risk_Factor"])
plt.show()

# Separate features (X) and target (y)
X = df.drop(columns=["Biodiversity_Risk_Factor"])
y = df["Biodiversity_Risk_Factor"]

# Split into training and test datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Normalize the target variable (if needed)
target_scaler = MinMaxScaler()
y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))
y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))

# Define the model
def create_model():
    model = Sequential([
        Dense(64, activation="relu", input_shape=(X_train_scaled.shape[1],)),
        BatchNormalization(),
        Dropout(0.2),
        Dense(32, activation="relu"),
        BatchNormalization(),
        Dropout(0.1),
        Dense(16, activation="relu"),
        Dense(1, activation="linear")  # Linear activation for regression
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
        loss="mse",  # Mean Squared Error for regression
        metrics=["mae"]
    )
    return model

# Instantiate the model
model = create_model()

# Early stopping to prevent overfitting
early_stop = EarlyStopping(monitor="val_loss", patience=20, restore_best_weights=True)

# Train the model
history = model.fit(
    X_train_scaled, y_train_scaled,
    validation_data=(X_test_scaled, y_test_scaled),
    epochs=200,
    batch_size=64,
    callbacks=[early_stop],
    verbose=1
)

# Evaluate the model on the test set
test_loss, test_mae = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)
print(f"Test Loss (MSE): {test_loss:.4f}")
print(f"Test MAE: {test_mae:.4f}")

# Plot the training history
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss (MSE)")
plt.legend()
plt.show()

# Predict on new data
predictions = model.predict(X_test_scaled)

# Inverse transform predictions and actual values
y_pred = target_scaler.inverse_transform(predictions)
y_actual = target_scaler.inverse_transform(y_test_scaled)

# Example: Display a few predictions vs actual values
comparison_df = pd.DataFrame({"Actual": y_actual.flatten(), "Predicted": y_pred.flatten()})
print(comparison_df.head(10))

# Define function to make urban planning recommendations based on predictions
def urban_planning_recommendations(predicted_biodiversity_risk, urban_expansion, biodiversity_goals):
    recommendations = []

    # Analyze predicted biodiversity risk and make suggestions
    if predicted_biodiversity_risk > 0.7:  # High risk of biodiversity loss
        if urban_expansion:
            recommendations.append("Reduce urban expansion in areas with high biodiversity risk to preserve habitats.")
        if biodiversity_goals > 8:  # High priority for biodiversity goals
            recommendations.append("Create more green corridors to enhance wildlife movement between fragmented habitats.")
        recommendations.append("Incorporate native vegetation in new urban developments to improve ecosystem stability.")
        recommendations.append("Prioritize green infrastructure such as vertical gardens and green roofs.")

    elif predicted_biodiversity_risk > 0.4:  # Moderate risk of biodiversity loss
        recommendations.append("Encourage sustainable urban expansion with emphasis on preserving biodiversity-friendly zones.")
        recommendations.append("Enhance existing green spaces by planting native species to support local wildlife.")
        if biodiversity_goals > 6:  # Moderate priority for biodiversity goals
            recommendations.append("Develop buffer zones around sensitive areas to reduce impact from urbanization.")

    else:  # Low risk of biodiversity loss
        recommendations.append("Focus on maintaining current green spaces and biodiversity-friendly infrastructure.")
        if biodiversity_goals > 4:  # Low priority for biodiversity goals
            recommendations.append("Encourage urban parks with diverse plant species to create habitat variety.")

    return recommendations

# Example usage with predicted biodiversity risk score and user input
# Let's assume the predicted biodiversity risk score from the model is 0.85, urban expansion is True, and biodiversity goals are high (9)
predicted_biodiversity_risk_example = 0.85  # Example predicted score
urban_expansion_example = True
biodiversity_goals_example = 9

# Get the recommendations based on the inputs
recommendations = urban_planning_recommendations(predicted_biodiversity_risk_example, urban_expansion_example, biodiversity_goals_example)

# Display the recommendations
print("Urban Planning Recommendations based on Biodiversity Risk Prediction:")
for recommendation in recommendations:
    print(f"- {recommendation}")